{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T09:21:40.725344Z","iopub.status.busy":"2024-05-14T09:21:40.724399Z","iopub.status.idle":"2024-05-14T09:21:47.639446Z","shell.execute_reply":"2024-05-14T09:21:47.638691Z","shell.execute_reply.started":"2024-05-14T09:21:40.725301Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenization"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T09:21:47.641947Z","iopub.status.busy":"2024-05-14T09:21:47.641127Z","iopub.status.idle":"2024-05-14T17:52:08.695216Z","shell.execute_reply":"2024-05-14T17:52:08.694517Z","shell.execute_reply.started":"2024-05-14T09:21:47.641912Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-14 09:21:49.140305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-14 09:21:49.140435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-14 09:21:49.246900: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b1dc0c3c59467b974abef526af6544","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de074e002ca64fe8917508a1840dbe6a","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7eec1550efd64d01b9d8d80fa33b7c76","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b423765de3404cbb8968fb1ef519c0a7","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d547d3572024630b28af359b48bf69f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb4db0de166a4064af33fb8e01fee8ac","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"298a89a517124780b3131c9704e6962a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240514_092800-khrrtdzq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq' target=\"_blank\">helpful-waterfall-7</a></strong> to <a href='https://wandb.ai/epitalylian/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/epitalylian/huggingface' target=\"_blank\">https://wandb.ai/epitalylian/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq' target=\"_blank\">https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='38589' max='38589' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38589/38589 8:23:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.450600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.411800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.403600</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.386300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.379400</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.354500</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>3.365700</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.344200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.333300</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.334700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>3.332100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>3.325700</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>3.321700</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>3.311500</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>3.306500</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>3.303900</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>3.303000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>3.292900</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>3.288300</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>3.282100</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>3.284900</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>3.276200</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>3.283300</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>3.274100</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>3.278600</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>3.217300</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>3.109800</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>3.099600</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>3.096800</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>3.107900</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>3.092300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>3.104200</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>3.103000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>3.092700</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>3.103500</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>3.101400</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>3.098100</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>3.108300</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>3.107300</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>3.100000</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>3.094600</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>3.095800</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>3.089800</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>3.101100</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>3.100500</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>3.081700</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>3.089900</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>3.097800</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>3.089900</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>3.092200</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>3.082000</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>3.022300</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>2.967900</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>2.973000</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>2.969600</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>2.971100</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>2.968500</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>2.975400</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>2.969300</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>2.967400</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>2.977400</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>2.968100</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>2.974600</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>2.969200</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>2.964800</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>2.979700</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>2.967100</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>2.967800</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>2.971800</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>2.968200</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>2.969800</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>2.963300</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>2.967900</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>2.959400</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>2.961600</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>2.961600</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>2.956700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=38589, training_loss=3.1310325886895596, metrics={'train_runtime': 30479.448, 'train_samples_per_second': 10.128, 'train_steps_per_second': 1.266, 'total_flos': 7.16731726257193e+16, 'train_loss': 3.1310325886895596, 'epoch': 3.0})"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","\n","# Charger le tokenizer et le mod猫le\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n","\n","# Charger votre jeu de donn茅es  partir du fichier CSV\n","data = pd.read_csv(\"wiki_movie_plots_deduped.csv\") \n","\n","# Pr茅traiter les donn茅es et les sauvegarder dans un fichier texte\n","with open(\"dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for idx, row in data.iterrows():\n","        plot = row[\"Plot\"]\n","        genre = row[\"Genre\"]\n","        f.write(f\"<BOS> Genre: {genre} Plot: {plot}\\n\")\n","\n","# Charger le dataset  partir du fichier texte\n","train_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"dataset.txt\",\n","    block_size=128  # Taille maximale du bloc pour le mod猫le\n",")\n","\n","# Configuration des param猫tres d'entra卯nement\n","training_args = TrainingArguments(\n","    output_dir=\"./fine-tuned-gpt2\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n",")\n","\n","# Entra卯nement du mod猫le\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n","    train_dataset=train_dataset,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T17:52:08.696612Z","iopub.status.busy":"2024-05-14T17:52:08.696316Z","iopub.status.idle":"2024-05-14T17:52:10.929689Z","shell.execute_reply":"2024-05-14T17:52:10.928527Z","shell.execute_reply.started":"2024-05-14T17:52:08.696588Z"},"trusted":true},"outputs":[],"source":["# Chemin o霉 vous souhaitez enregistrer le mod猫le\n","output_dir = \"/kaggle/working/fine-tuned-gpt2\"\n","\n","# Enregistrer le mod猫le fine-tuned\n","model.save_pretrained(output_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# Test\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T17:52:10.936498Z","iopub.status.busy":"2024-05-14T17:52:10.935752Z","iopub.status.idle":"2024-05-14T17:52:46.383493Z","shell.execute_reply":"2024-05-14T17:52:46.382394Z","shell.execute_reply.started":"2024-05-14T17:52:10.936455Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Intrigue de film pour le genre Comedy: <BOS> Genre: Comedy Plot: The film opens with a young man named Michael (Michael Rennie) who is a student at a local college. He is a bit of a loner, and is always in trouble with his friends. One day, he meets a girl named Sarah (Sarah Silverman), who is a student at the same college. They both fall in love with each other, and they decide to get married.\n","Michael's father, a lawyer, is a very strict man, and he is very strict with his son. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son,\n","------------------------\n","Intrigue de film pour le genre Action: <BOS> Genre: Action Plot: The film opens with a young man named Raju (Rajesh Khanna) who is a student of the same college as his father. Raju is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who\n","CPU times: user 1min 9s, sys: 1.01 s, total: 1min 10s\n","Wall time: 35.4 s\n"]}],"source":["%%time\n","# Charger le tokenizer et le mod猫le fine-tuned\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")  # Chemin vers le mod猫le fine-tuned\n","model = GPT2LMHeadModel.from_pretrained(\"/kaggle/working/fine-tuned-gpt2\")  # Chemin vers le mod猫le fine-tuned\n","\n","# Fonction pour g茅n茅rer une intrigue  partir d'un genre\n","def generate_plot(genre):\n","    # Pr茅parer l'entr茅e pour le mod猫le (ajout de tokens sp茅ciaux)\n","    input_text = \"<BOS> Genre: \" + genre + \" Plot:\"\n","\n","    # Convertir l'entr茅e en tokens\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","    # Utiliser le mod猫le pour g茅n茅rer une suite de texte\n","    output = model.generate(input_ids, max_length=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","\n","    # D茅coder la sortie en texte\n","    plot = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return plot\n","\n","\n","genre = \"Comedy\"\n","intrigue = generate_plot(genre)\n","print(\"Intrigue de film pour le genre\", genre + \":\", intrigue)\n","\n","print(\"------------------------\")\n","genre = \"Action\"\n","intrigue = generate_plot(genre)\n","print(\"Intrigue de film pour le genre\", genre + \":\", intrigue)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4868319,"sourceId":8213978,"sourceType":"datasetVersion"},{"datasetId":4869301,"sourceId":8215344,"sourceType":"datasetVersion"},{"datasetId":4961816,"sourceId":8351257,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
