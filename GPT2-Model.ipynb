{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T09:21:40.725344Z","iopub.status.busy":"2024-05-14T09:21:40.724399Z","iopub.status.idle":"2024-05-14T09:21:47.639446Z","shell.execute_reply":"2024-05-14T09:21:47.638691Z","shell.execute_reply.started":"2024-05-14T09:21:40.725301Z"},"trusted":true},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"markdown","metadata":{},"source":["# Tokenization"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T09:21:47.641947Z","iopub.status.busy":"2024-05-14T09:21:47.641127Z","iopub.status.idle":"2024-05-14T17:52:08.695216Z","shell.execute_reply":"2024-05-14T17:52:08.694517Z","shell.execute_reply.started":"2024-05-14T09:21:47.641912Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-14 09:21:49.140305: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-14 09:21:49.140435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-14 09:21:49.246900: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b1dc0c3c59467b974abef526af6544","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de074e002ca64fe8917508a1840dbe6a","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7eec1550efd64d01b9d8d80fa33b7c76","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b423765de3404cbb8968fb1ef519c0a7","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d547d3572024630b28af359b48bf69f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb4db0de166a4064af33fb8e01fee8ac","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"298a89a517124780b3131c9704e6962a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240514_092800-khrrtdzq</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq' target=\"_blank\">helpful-waterfall-7</a></strong> to <a href='https://wandb.ai/epitalylian/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/epitalylian/huggingface' target=\"_blank\">https://wandb.ai/epitalylian/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq' target=\"_blank\">https://wandb.ai/epitalylian/huggingface/runs/khrrtdzq</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='38589' max='38589' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [38589/38589 8:23:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.450600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.411800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.403600</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.386300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>3.379400</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.354500</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>3.365700</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.344200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.333300</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.334700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>3.332100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>3.325700</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>3.321700</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>3.311500</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>3.306500</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>3.303900</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>3.303000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>3.292900</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>3.288300</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>3.282100</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>3.284900</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>3.276200</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>3.283300</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>3.274100</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>3.278600</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>3.217300</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>3.109800</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>3.099600</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>3.096800</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>3.107900</td>\n","    </tr>\n","    <tr>\n","      <td>15500</td>\n","      <td>3.092300</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>3.104200</td>\n","    </tr>\n","    <tr>\n","      <td>16500</td>\n","      <td>3.103000</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>3.092700</td>\n","    </tr>\n","    <tr>\n","      <td>17500</td>\n","      <td>3.103500</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>3.101400</td>\n","    </tr>\n","    <tr>\n","      <td>18500</td>\n","      <td>3.098100</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>3.108300</td>\n","    </tr>\n","    <tr>\n","      <td>19500</td>\n","      <td>3.107300</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>3.100000</td>\n","    </tr>\n","    <tr>\n","      <td>20500</td>\n","      <td>3.094600</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>3.095800</td>\n","    </tr>\n","    <tr>\n","      <td>21500</td>\n","      <td>3.089800</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>3.101100</td>\n","    </tr>\n","    <tr>\n","      <td>22500</td>\n","      <td>3.100500</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>3.081700</td>\n","    </tr>\n","    <tr>\n","      <td>23500</td>\n","      <td>3.089900</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>3.097800</td>\n","    </tr>\n","    <tr>\n","      <td>24500</td>\n","      <td>3.089900</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>3.092200</td>\n","    </tr>\n","    <tr>\n","      <td>25500</td>\n","      <td>3.082000</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>3.022300</td>\n","    </tr>\n","    <tr>\n","      <td>26500</td>\n","      <td>2.967900</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>2.973000</td>\n","    </tr>\n","    <tr>\n","      <td>27500</td>\n","      <td>2.969600</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>2.971100</td>\n","    </tr>\n","    <tr>\n","      <td>28500</td>\n","      <td>2.968500</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>2.975400</td>\n","    </tr>\n","    <tr>\n","      <td>29500</td>\n","      <td>2.969300</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>2.967400</td>\n","    </tr>\n","    <tr>\n","      <td>30500</td>\n","      <td>2.977400</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>2.968100</td>\n","    </tr>\n","    <tr>\n","      <td>31500</td>\n","      <td>2.974600</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>2.969200</td>\n","    </tr>\n","    <tr>\n","      <td>32500</td>\n","      <td>2.964800</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>2.979700</td>\n","    </tr>\n","    <tr>\n","      <td>33500</td>\n","      <td>2.967100</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>2.967800</td>\n","    </tr>\n","    <tr>\n","      <td>34500</td>\n","      <td>2.971800</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>2.968200</td>\n","    </tr>\n","    <tr>\n","      <td>35500</td>\n","      <td>2.969800</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>2.963300</td>\n","    </tr>\n","    <tr>\n","      <td>36500</td>\n","      <td>2.967900</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>2.959400</td>\n","    </tr>\n","    <tr>\n","      <td>37500</td>\n","      <td>2.961600</td>\n","    </tr>\n","    <tr>\n","      <td>38000</td>\n","      <td>2.961600</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>2.956700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=38589, training_loss=3.1310325886895596, metrics={'train_runtime': 30479.448, 'train_samples_per_second': 10.128, 'train_steps_per_second': 1.266, 'total_flos': 7.16731726257193e+16, 'train_loss': 3.1310325886895596, 'epoch': 3.0})"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","\n","# Charger le tokenizer et le modèle\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n","\n","# Charger votre jeu de données à partir du fichier CSV\n","data = pd.read_csv(\"wiki_movie_plots_deduped.csv\") \n","\n","# Prétraiter les données et les sauvegarder dans un fichier texte\n","with open(\"dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for idx, row in data.iterrows():\n","        plot = row[\"Plot\"]\n","        genre = row[\"Genre\"]\n","        f.write(f\"<BOS> Genre: {genre} Plot: {plot}\\n\")\n","\n","# Charger le dataset à partir du fichier texte\n","train_dataset = TextDataset(\n","    tokenizer=tokenizer,\n","    file_path=\"dataset.txt\",\n","    block_size=128  # Taille maximale du bloc pour le modèle\n",")\n","\n","# Configuration des paramètres d'entraînement\n","training_args = TrainingArguments(\n","    output_dir=\"./fine-tuned-gpt2\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    save_steps=10_000,\n","    save_total_limit=2,\n",")\n","\n","# Entraînement du modèle\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n","    train_dataset=train_dataset,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T17:52:08.696612Z","iopub.status.busy":"2024-05-14T17:52:08.696316Z","iopub.status.idle":"2024-05-14T17:52:10.929689Z","shell.execute_reply":"2024-05-14T17:52:10.928527Z","shell.execute_reply.started":"2024-05-14T17:52:08.696588Z"},"trusted":true},"outputs":[],"source":["# Chemin où vous souhaitez enregistrer le modèle\n","output_dir = \"/kaggle/working/fine-tuned-gpt2\"\n","\n","# Enregistrer le modèle fine-tuned\n","model.save_pretrained(output_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# Test\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T17:52:10.936498Z","iopub.status.busy":"2024-05-14T17:52:10.935752Z","iopub.status.idle":"2024-05-14T17:52:46.383493Z","shell.execute_reply":"2024-05-14T17:52:46.382394Z","shell.execute_reply.started":"2024-05-14T17:52:10.936455Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Intrigue de film pour le genre Comedy: <BOS> Genre: Comedy Plot: The film opens with a young man named Michael (Michael Rennie) who is a student at a local college. He is a bit of a loner, and is always in trouble with his friends. One day, he meets a girl named Sarah (Sarah Silverman), who is a student at the same college. They both fall in love with each other, and they decide to get married.\n","Michael's father, a lawyer, is a very strict man, and he is very strict with his son. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son, and he is very strict with his father. Michael's father is very strict with his son,\n","------------------------\n","Intrigue de film pour le genre Action: <BOS> Genre: Action Plot: The film opens with a young man named Raju (Rajesh Khanna) who is a student of the same college as his father. Raju is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who is always in trouble with the law. He is a typical student who\n","CPU times: user 1min 9s, sys: 1.01 s, total: 1min 10s\n","Wall time: 35.4 s\n"]}],"source":["%%time\n","# Charger le tokenizer et le modèle fine-tuned\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")  # Chemin vers le modèle fine-tuned\n","model = GPT2LMHeadModel.from_pretrained(\"/kaggle/working/fine-tuned-gpt2\")  # Chemin vers le modèle fine-tuned\n","\n","# Fonction pour générer une intrigue à partir d'un genre\n","def generate_plot(genre):\n","    # Préparer l'entrée pour le modèle (ajout de tokens spéciaux)\n","    input_text = \"<BOS> Genre: \" + genre + \" Plot:\"\n","\n","    # Convertir l'entrée en tokens\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","    # Utiliser le modèle pour générer une suite de texte\n","    output = model.generate(input_ids, max_length=200, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","\n","    # Décoder la sortie en texte\n","    plot = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    return plot\n","\n","\n","genre = \"Comedy\"\n","intrigue = generate_plot(genre)\n","print(\"Intrigue de film pour le genre\", genre + \":\", intrigue)\n","\n","print(\"------------------------\")\n","genre = \"Action\"\n","intrigue = generate_plot(genre)\n","print(\"Intrigue de film pour le genre\", genre + \":\", intrigue)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4868319,"sourceId":8213978,"sourceType":"datasetVersion"},{"datasetId":4869301,"sourceId":8215344,"sourceType":"datasetVersion"},{"datasetId":4961816,"sourceId":8351257,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
